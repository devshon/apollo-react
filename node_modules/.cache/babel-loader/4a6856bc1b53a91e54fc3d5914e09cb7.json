{"ast":null,"code":"\"use strict\";\n\nvar __assign = this && this.__assign || function () {\n  __assign = Object.assign || function (t) {\n    for (var s, i = 1, n = arguments.length; i < n; i++) {\n      s = arguments[i];\n\n      for (var p in s) if (Object.prototype.hasOwnProperty.call(s, p)) t[p] = s[p];\n    }\n\n    return t;\n  };\n\n  return __assign.apply(this, arguments);\n};\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\n\nvar fs = require(\"fs\");\n\nvar graphql_1 = require(\"graphql\");\n\nvar lodash_1 = require(\"lodash\");\n\nvar path = require(\"path\");\n\nvar resolveFrom = require(\"resolve-from\");\n\nvar definition_1 = require(\"./definition\");\n\nvar rootFields = ['Query', 'Mutation', 'Subscription'];\n\nvar read = function (schema, schemas) {\n  if (isFile(schema)) {\n    return fs.readFileSync(schema, {\n      encoding: 'utf8'\n    });\n  }\n\n  return schemas ? schemas[schema] : schema;\n};\n\nvar isFile = function (f) {\n  return f.endsWith('.graphql');\n};\n/**\n * Parse a single import line and extract imported types and schema filename\n *\n * @param importLine Import line\n * @returns Processed import line\n */\n\n\nfunction parseImportLine(importLine) {\n  // Apply regex to import line\n  var matches = importLine.match(/^import (\\*|(.*)) from ('|\")(.*)('|\");?$/);\n\n  if (!matches || matches.length !== 6 || !matches[4]) {\n    throw new Error(\"Too few regex matches: \" + matches);\n  } // Extract matches into named variables\n\n\n  var wildcard = matches[1],\n      importsString = matches[2],\n      from = matches[4]; // Extract imported types\n\n  var imports = wildcard === '*' ? ['*'] : importsString.split(',').map(function (d) {\n    return d.trim();\n  }); // Return information about the import line\n\n  return {\n    imports: imports,\n    from: from\n  };\n}\n\nexports.parseImportLine = parseImportLine;\n/**\n * Parse a schema and analyze all import lines\n *\n * @param sdl Schema to parse\n * @returns Array with collection of imports per import line (file)\n */\n\nfunction parseSDL(sdl) {\n  return sdl.split('\\n').map(function (l) {\n    return l.trim();\n  }).filter(function (l) {\n    return l.startsWith('# import ') || l.startsWith('#import ');\n  }).map(function (l) {\n    return l.replace('#', '').trim();\n  }).map(parseImportLine);\n}\n\nexports.parseSDL = parseSDL;\n/**\n * Main entry point. Recursively process all import statement in a schema\n *\n * @param filePath File path to the initial schema file\n * @returns Single bundled schema with all imported types\n */\n\nfunction importSchema(schema, schemas) {\n  var sdl = read(schema, schemas) || schema;\n  var document = getDocumentFromSDL(sdl); // Recursively process the imports, starting by importing all types from the initial schema\n\n  var _a = collectDefinitions(['*'], sdl, schema, schemas),\n      allDefinitions = _a.allDefinitions,\n      typeDefinitions = _a.typeDefinitions; // Post processing of the final schema (missing types, unused types, etc.)\n  // Query, Mutation and Subscription should be merged\n  // And should always be in the first set, to make sure they\n  // are not filtered out.\n\n\n  var firstTypes = lodash_1.flatten(typeDefinitions).filter(function (d) {\n    return lodash_1.includes(rootFields, d.name.value);\n  });\n  var otherFirstTypes = typeDefinitions[0].filter(function (d) {\n    return !lodash_1.includes(rootFields, d.name.value);\n  });\n  var firstSet = firstTypes.concat(otherFirstTypes);\n  var processedTypeNames = [];\n  var mergedFirstTypes = [];\n\n  var _loop_1 = function (type) {\n    if (!lodash_1.includes(processedTypeNames, type.name.value)) {\n      processedTypeNames.push(type.name.value);\n      mergedFirstTypes.push(type);\n    } else {\n      var existingType = mergedFirstTypes.find(function (t) {\n        return t.name.value === type.name.value;\n      });\n      existingType.fields = existingType.fields.concat(type.fields);\n    }\n  };\n\n  for (var _i = 0, firstSet_1 = firstSet; _i < firstSet_1.length; _i++) {\n    var type = firstSet_1[_i];\n\n    _loop_1(type);\n  }\n\n  document = __assign({}, document, {\n    definitions: definition_1.completeDefinitionPool(lodash_1.flatten(allDefinitions), firstSet, lodash_1.flatten(typeDefinitions))\n  }); // Return the schema as string\n\n  return graphql_1.print(document);\n}\n\nexports.importSchema = importSchema;\n/**\n * Parses a schema into a graphql DocumentNode.\n * If the schema is empty a DocumentNode with empty definitions will be created.\n *\n * @param sdl Schema to parse\n * @returns A graphql DocumentNode with definitions of the parsed sdl.\n */\n\nfunction getDocumentFromSDL(sdl) {\n  if (isEmptySDL(sdl)) {\n    return {\n      kind: graphql_1.Kind.DOCUMENT,\n      definitions: []\n    };\n  } else {\n    return graphql_1.parse(sdl, {\n      noLocation: true\n    });\n  }\n}\n/**\n * Check if a schema contains any type definitions at all.\n *\n * @param sdl Schema to parse\n * @returns True if SDL only contains comments and/or whitespaces\n */\n\n\nfunction isEmptySDL(sdl) {\n  return sdl.split('\\n').map(function (l) {\n    return l.trim();\n  }).filter(function (l) {\n    return !(l.length === 0 || l.startsWith('#'));\n  }).length === 0;\n}\n/**\n * Resolve the path of an import.\n * First it will try to find a file relative from the file the import is in, if that fails it will try to resolve it as a module so imports from packages work correctly.\n *\n * @param filePath Path the import was made from\n * @param importFrom Path given for the import\n * @returns Full resolved path to a file\n */\n\n\nfunction resolveModuleFilePath(filePath, importFrom) {\n  var dirname = path.dirname(filePath);\n\n  if (isFile(filePath) && isFile(importFrom)) {\n    try {\n      return fs.realpathSync(path.join(dirname, importFrom));\n    } catch (e) {\n      if (e.code === 'ENOENT') {\n        return resolveFrom(dirname, importFrom);\n      }\n    }\n  }\n\n  return importFrom;\n}\n/**\n * Recursively process all schema files. Keeps track of both the filtered\n * type definitions, and all type definitions, because they might be needed\n * in post-processing (to add missing types)\n *\n * @param imports Types specified in the import statement\n * @param sdl Current schema\n * @param filePath File location for current schema\n * @param Tracking of processed schemas (for circular dependencies)\n * @param Tracking of imported type definitions per schema\n * @param Tracking of all type definitions per schema\n * @returns Both the collection of all type definitions, and the collection of imported type definitions\n */\n\n\nfunction collectDefinitions(imports, sdl, filePath, schemas, processedFiles, typeDefinitions, allDefinitions) {\n  if (processedFiles === void 0) {\n    processedFiles = new Map();\n  }\n\n  if (typeDefinitions === void 0) {\n    typeDefinitions = [];\n  }\n\n  if (allDefinitions === void 0) {\n    allDefinitions = [];\n  }\n\n  var key = isFile(filePath) ? path.resolve(filePath) : filePath; // Get TypeDefinitionNodes from current schema\n\n  var document = getDocumentFromSDL(sdl); // Add all definitions to running total\n\n  allDefinitions.push(filterTypeDefinitions(document.definitions)); // Filter TypeDefinitionNodes by type and defined imports\n\n  var currentTypeDefinitions = filterImportedDefinitions(imports, document.definitions, allDefinitions); // Add typedefinitions to running total\n\n  typeDefinitions.push(currentTypeDefinitions); // Read imports from current file\n\n  var rawModules = parseSDL(sdl); // Process each file (recursively)\n\n  rawModules.forEach(function (m) {\n    // If it was not yet processed (in case of circular dependencies)\n    var moduleFilePath = resolveModuleFilePath(filePath, m.from);\n    var processedFile = processedFiles.get(key);\n\n    if (!processedFile || !processedFile.find(function (rModule) {\n      return lodash_1.isEqual(rModule, m);\n    })) {\n      // Mark this specific import line as processed for this file (for cicular dependency cases)\n      processedFiles.set(key, processedFile ? processedFile.concat(m) : [m]);\n      collectDefinitions(m.imports, read(moduleFilePath, schemas), moduleFilePath, schemas, processedFiles, typeDefinitions, allDefinitions);\n    }\n  }); // Return the maps of type definitions from each file\n\n  return {\n    allDefinitions: allDefinitions,\n    typeDefinitions: typeDefinitions\n  };\n}\n/**\n * Filter the types loaded from a schema, first by relevant types,\n * then by the types specified in the import statement.\n *\n * @param imports Types specified in the import statement\n * @param typeDefinitions All definitions from a schema\n * @returns Filtered collection of type definitions\n */\n\n\nfunction filterImportedDefinitions(imports, typeDefinitions, allDefinitions) {\n  // This should do something smart with fields\n  if (allDefinitions === void 0) {\n    allDefinitions = [];\n  }\n\n  var filteredDefinitions = filterTypeDefinitions(typeDefinitions);\n\n  if (lodash_1.includes(imports, '*')) {\n    if (imports.length === 1 && imports[0] === '*' && allDefinitions.length > 1) {\n      var previousTypeDefinitions_1 = lodash_1.keyBy(lodash_1.flatten(allDefinitions.slice(0, allDefinitions.length - 1)).filter(function (def) {\n        return !lodash_1.includes(rootFields, def.name.value);\n      }), function (def) {\n        return def.name.value;\n      });\n      return typeDefinitions.filter(function (typeDef) {\n        return typeDef.kind === 'ObjectTypeDefinition' && previousTypeDefinitions_1[typeDef.name.value];\n      });\n    }\n\n    return filteredDefinitions;\n  } else {\n    var result = filteredDefinitions.filter(function (d) {\n      return lodash_1.includes(imports.map(function (i) {\n        return i.split('.')[0];\n      }), d.name.value);\n    });\n    var fieldImports = imports.filter(function (i) {\n      return i.split('.').length > 1;\n    });\n    var groupedFieldImports = lodash_1.groupBy(fieldImports, function (x) {\n      return x.split('.')[0];\n    });\n\n    var _loop_2 = function (rootType) {\n      var fields = groupedFieldImports[rootType].map(function (x) {\n        return x.split('.')[1];\n      });\n      filteredDefinitions.find(function (def) {\n        return def.name.value === rootType;\n      }).fields = filteredDefinitions.find(function (def) {\n        return def.name.value === rootType;\n      }).fields.filter(function (f) {\n        return lodash_1.includes(fields, f.name.value) || lodash_1.includes(fields, '*');\n      });\n    };\n\n    for (var rootType in groupedFieldImports) {\n      _loop_2(rootType);\n    }\n\n    return result;\n  }\n}\n/**\n * Filter relevant definitions from schema\n *\n * @param definitions All definitions from a schema\n * @returns Relevant type definitions\n */\n\n\nfunction filterTypeDefinitions(definitions) {\n  var validKinds = ['DirectiveDefinition', 'ScalarTypeDefinition', 'ObjectTypeDefinition', 'InterfaceTypeDefinition', 'EnumTypeDefinition', 'UnionTypeDefinition', 'InputObjectTypeDefinition'];\n  return definitions.filter(function (d) {\n    return lodash_1.includes(validKinds, d.kind);\n  }).map(function (d) {\n    return d;\n  });\n}","map":{"version":3,"sources":["../src/index.ts"],"names":[],"mappings":";;;;;;;;;;;;;;;;;;;;AAAA,IAAA,EAAA,GAAA,OAAA,CAAA,IAAA,CAAA;;AACA,IAAA,SAAA,GAAA,OAAA,CAAA,SAAA,CAAA;;AAUA,IAAA,QAAA,GAAA,OAAA,CAAA,QAAA,CAAA;;AACA,IAAA,IAAA,GAAA,OAAA,CAAA,MAAA,CAAA;;AACA,IAAA,WAAA,GAAA,OAAA,CAAA,cAAA,CAAA;;AAEA,IAAA,YAAA,GAAA,OAAA,CAAA,cAAA,CAAA;;AAWA,IAAM,UAAU,GAAG,CAAC,OAAD,EAAU,UAAV,EAAsB,cAAtB,CAAnB;;AAEA,IAAM,IAAI,GAAG,UAAC,MAAD,EAAiB,OAAjB,EAAoD;AAC/D,MAAI,MAAM,CAAC,MAAD,CAAV,EAAoB;AAClB,WAAO,EAAE,CAAC,YAAH,CAAgB,MAAhB,EAAwB;AAAE,MAAA,QAAQ,EAAE;AAAZ,KAAxB,CAAP;AACD;;AACD,SAAO,OAAO,GAAG,OAAO,CAAC,MAAD,CAAV,GAAqB,MAAnC;AACD,CALD;;AAOA,IAAM,MAAM,GAAG,UAAA,CAAA,EAAC;AAAI,SAAA,CAAC,CAAC,QAAF,CAAA,UAAA,CAAA;AAAsB,CAA1C;AAEA;;;;;AAKG;;;AACH,SAAgB,eAAhB,CAAgC,UAAhC,EAAkD;AAChD;AACA,MAAM,OAAO,GAAG,UAAU,CAAC,KAAX,CAAiB,0CAAjB,CAAhB;;AACA,MAAI,CAAC,OAAD,IAAY,OAAO,CAAC,MAAR,KAAmB,CAA/B,IAAoC,CAAC,OAAO,CAAC,CAAD,CAAhD,EAAqD;AACnD,UAAM,IAAI,KAAJ,CAAU,4BAA0B,OAApC,CAAN;AACD,GAL+C,CAOhD;;;AACS,MAAA,QAAA,GAAA,OAAA,CAAA,CAAA,CAAA;AAAA,MAAU,aAAA,GAAA,OAAA,CAAA,CAAA,CAAV;AAAA,MAA2B,IAAA,GAAA,OAAA,CAAA,CAAA,CAA3B,CARuC,CAUhD;;AACA,MAAM,OAAO,GACX,QAAQ,KAAK,GAAb,GAAmB,CAAC,GAAD,CAAnB,GAA2B,aAAa,CAAC,KAAd,CAAoB,GAApB,EAAyB,GAAzB,CAA6B,UAAA,CAAA,EAAC;AAAI,WAAA,CAAC,CAAD,IAAA,EAAA;AAAQ,GAA1C,CAD7B,CAXgD,CAchD;;AACA,SAAO;AAAE,IAAA,OAAO,EAAA,OAAT;AAAW,IAAA,IAAI,EAAA;AAAf,GAAP;AACD;;AAhBD,OAAA,CAAA,eAAA,GAAA,eAAA;AAkBA;;;;;AAKG;;AACH,SAAgB,QAAhB,CAAyB,GAAzB,EAAoC;AAClC,SAAO,GAAG,CACP,KADI,CACE,IADF,EAEJ,GAFI,CAEA,UAAA,CAAA,EAAC;AAAI,WAAA,CAAC,CAAD,IAAA,EAAA;AAAQ,GAFb,EAGJ,MAHI,CAGG,UAAA,CAAA,EAAC;AAAI,WAAA,CAAC,CAAC,UAAF,CAAa,WAAb,KAA6B,CAAC,CAAC,UAAF,CAA7B,UAA6B,CAA7B;AAAqD,GAH7D,EAIJ,GAJI,CAIA,UAAA,CAAA,EAAC;AAAI,WAAA,CAAC,CAAC,OAAF,CAAU,GAAV,EAAe,EAAf,EAAA,IAAA,EAAA;AAAyB,GAJ9B,EAKJ,GALI,CAKA,eALA,CAAP;AAMD;;AAPD,OAAA,CAAA,QAAA,GAAA,QAAA;AASA;;;;;AAKG;;AACH,SAAgB,YAAhB,CACE,MADF,EAEE,OAFF,EAEqC;AAEnC,MAAM,GAAG,GAAG,IAAI,CAAC,MAAD,EAAS,OAAT,CAAJ,IAAyB,MAArC;AACA,MAAI,QAAQ,GAAG,kBAAkB,CAAC,GAAD,CAAjC,CAHmC,CAKnC;;AACI,MAAA,EAAA,GAAA,kBAAA,CAAA,CAAA,GAAA,CAAA,EAAA,GAAA,EAAA,MAAA,EAAA,OAAA,CAAA;AAAA,MAAE,cAAA,GAAA,EAAA,CAAA,cAAF;AAAA,MAAkB,eAAA,GAAA,EAAA,CAAA,eAAlB,CAN+B,CAanC;AACA;AACA;AACA;;;AACA,MAAM,UAAU,GAAG,QAAA,CAAA,OAAA,CAAQ,eAAR,EAAyB,MAAzB,CAAgC,UAAA,CAAA,EAAC;AAClD,WAAA,QAAA,CAAA,QAAA,CAAS,UAAT,EAAqB,CAAC,CAAC,IAAF,CAAO,KAA5B,CAAA;AAAkC,GADjB,CAAnB;AAGA,MAAM,eAAe,GAAG,eAAe,CAAC,CAAD,CAAf,CAAmB,MAAnB,CACtB,UAAA,CAAA,EAAC;AAAI,WAAA,CAAC,QAAA,CAAA,QAAA,CAAS,UAAT,EAAqB,CAAC,CAAC,IAAF,CAAtB,KAAC,CAAD;AAAmC,GADlB,CAAxB;AAGA,MAAM,QAAQ,GAAG,UAAU,CAAC,MAAX,CAAkB,eAAlB,CAAjB;AACA,MAAM,kBAAkB,GAAG,EAA3B;AACA,MAAM,gBAAgB,GAAG,EAAzB;;0BACW,I,EAAI;AACb,QAAI,CAAC,QAAA,CAAA,QAAA,CAAS,kBAAT,EAA6B,IAAI,CAAC,IAAL,CAAU,KAAvC,CAAL,EAAoD;AAClD,MAAA,kBAAkB,CAAC,IAAnB,CAAwB,IAAI,CAAC,IAAL,CAAU,KAAlC;AACA,MAAA,gBAAgB,CAAC,IAAjB,CAAsB,IAAtB;AACD,KAHD,MAGO;AACL,UAAM,YAAY,GAAG,gBAAgB,CAAC,IAAjB,CACnB,UAAA,CAAA,EAAC;AAAI,eAAA,CAAC,CAAC,IAAF,CAAO,KAAP,KAAiB,IAAI,CAAC,IAAL,CAAjB,KAAA;AAAgC,OADlB,CAArB;AAGA,MAAA,YAAY,CAAC,MAAb,GAAsB,YAAY,CAAC,MAAb,CAAoB,MAApB,CACnB,IAAiC,CAAC,MADf,CAAtB;AAGD;AACF,G;;AAZD,OAAmB,IAAA,EAAA,GAAA,CAAA,EAAA,UAAA,GAAA,QAAnB,EAAmB,EAAA,GAAA,UAAA,CAAA,MAAnB,EAAmB,EAAA,EAAnB,EAA2B;AAAtB,QAAM,IAAI,GAAA,UAAA,CAAA,EAAA,CAAV;;YAAM,I;AAYV;;AAED,EAAA,QAAQ,GAAA,QAAA,CAAA,EAAA,EACH,QADG,EACK;AACX,IAAA,WAAW,EAAE,YAAA,CAAA,sBAAA,CACX,QAAA,CAAA,OAAA,CAAQ,cAAR,CADW,EAEX,QAFW,EAGX,QAAA,CAAA,OAAA,CAAQ,eAAR,CAHW;AADF,GADL,CAAR,CAxCmC,CAgDnC;;AACA,SAAO,SAAA,CAAA,KAAA,CAAM,QAAN,CAAP;AACD;;AApDD,OAAA,CAAA,YAAA,GAAA,YAAA;AAsDA;;;;;;AAMG;;AACH,SAAS,kBAAT,CAA4B,GAA5B,EAAuC;AACrC,MAAI,UAAU,CAAC,GAAD,CAAd,EAAqB;AACnB,WAAO;AACL,MAAA,IAAI,EAAE,SAAA,CAAA,IAAA,CAAK,QADN;AAEL,MAAA,WAAW,EAAE;AAFR,KAAP;AAID,GALD,MAKO;AACL,WAAO,SAAA,CAAA,KAAA,CAAM,GAAN,EAAW;AAAE,MAAA,UAAU,EAAE;AAAd,KAAX,CAAP;AACD;AACF;AAED;;;;;AAKG;;;AACH,SAAS,UAAT,CAAoB,GAApB,EAA+B;AAC7B,SACE,GAAG,CACA,KADH,CACS,IADT,EAEG,GAFH,CAEO,UAAA,CAAA,EAAC;AAAI,WAAA,CAAC,CAAD,IAAA,EAAA;AAAQ,GAFpB,EAGG,MAHH,CAGU,UAAA,CAAA,EAAC;AAAI,WAAA,EAAE,CAAC,CAAC,MAAF,KAAa,CAAb,IAAkB,CAAC,CAAC,UAAF,CAApB,GAAoB,CAApB,CAAA;AAAsC,GAHrD,EAGuD,MAHvD,KAGkE,CAJpE;AAMD;AAED;;;;;;;AAOG;;;AACH,SAAS,qBAAT,CAA+B,QAA/B,EAAiD,UAAjD,EAAmE;AACjE,MAAM,OAAO,GAAG,IAAI,CAAC,OAAL,CAAa,QAAb,CAAhB;;AACA,MAAI,MAAM,CAAC,QAAD,CAAN,IAAoB,MAAM,CAAC,UAAD,CAA9B,EAA4C;AAC1C,QAAI;AACF,aAAO,EAAE,CAAC,YAAH,CAAgB,IAAI,CAAC,IAAL,CAAU,OAAV,EAAmB,UAAnB,CAAhB,CAAP;AACD,KAFD,CAEE,OAAO,CAAP,EAAU;AACV,UAAI,CAAC,CAAC,IAAF,KAAW,QAAf,EAAyB;AACvB,eAAO,WAAW,CAAC,OAAD,EAAU,UAAV,CAAlB;AACD;AACF;AACF;;AAED,SAAO,UAAP;AACD;AAED;;;;;;;;;;;;AAYG;;;AACH,SAAS,kBAAT,CACE,OADF,EAEE,GAFF,EAGE,QAHF,EAIE,OAJF,EAKE,cALF,EAME,eANF,EAOE,cAPF,EAO8C;AAF5C,MAAA,cAAA,KAAA,KAAA,CAAA,EAAA;AAAA,IAAA,cAAA,GAAA,IAA+C,GAA/C,EAAA;AAAoD;;AACpD,MAAA,eAAA,KAAA,KAAA,CAAA,EAAA;AAAA,IAAA,eAAA,GAAA,EAAA;AAA6C;;AAC7C,MAAA,cAAA,KAAA,KAAA,CAAA,EAAA;AAAA,IAAA,cAAA,GAAA,EAAA;AAA4C;;AAK5C,MAAM,GAAG,GAAG,MAAM,CAAC,QAAD,CAAN,GAAmB,IAAI,CAAC,OAAL,CAAa,QAAb,CAAnB,GAA4C,QAAxD,CAL4C,CAO5C;;AACA,MAAM,QAAQ,GAAG,kBAAkB,CAAC,GAAD,CAAnC,CAR4C,CAU5C;;AACA,EAAA,cAAc,CAAC,IAAf,CAAoB,qBAAqB,CAAC,QAAQ,CAAC,WAAV,CAAzC,EAX4C,CAa5C;;AACA,MAAM,sBAAsB,GAAG,yBAAyB,CACtD,OADsD,EAEtD,QAAQ,CAAC,WAF6C,EAGtD,cAHsD,CAAxD,CAd4C,CAoB5C;;AACA,EAAA,eAAe,CAAC,IAAhB,CAAqB,sBAArB,EArB4C,CAuB5C;;AACA,MAAM,UAAU,GAAG,QAAQ,CAAC,GAAD,CAA3B,CAxB4C,CA0B5C;;AACA,EAAA,UAAU,CAAC,OAAX,CAAmB,UAAA,CAAA,EAAC;AAClB;AACA,QAAM,cAAc,GAAG,qBAAqB,CAAC,QAAD,EAAW,CAAC,CAAC,IAAb,CAA5C;AAEA,QAAM,aAAa,GAAG,cAAc,CAAC,GAAf,CAAmB,GAAnB,CAAtB;;AACA,QAAI,CAAC,aAAD,IAAkB,CAAC,aAAa,CAAC,IAAd,CAAmB,UAAA,OAAA,EAAO;AAAI,aAAA,QAAA,CAAA,OAAA,CAAQ,OAAR,EAAA,CAAA,CAAA;AAAmB,KAAjD,CAAvB,EAA2E;AACzE;AACA,MAAA,cAAc,CAAC,GAAf,CAAmB,GAAnB,EAAwB,aAAa,GAAG,aAAa,CAAC,MAAd,CAAqB,CAArB,CAAH,GAA6B,CAAC,CAAD,CAAlE;AACA,MAAA,kBAAkB,CAChB,CAAC,CAAC,OADc,EAEhB,IAAI,CAAC,cAAD,EAAiB,OAAjB,CAFY,EAGhB,cAHgB,EAIhB,OAJgB,EAKhB,cALgB,EAMhB,eANgB,EAOhB,cAPgB,CAAlB;AASD;AACF,GAlBD,EA3B4C,CA+C5C;;AACA,SAAO;AAAE,IAAA,cAAc,EAAA,cAAhB;AAAkB,IAAA,eAAe,EAAA;AAAjC,GAAP;AACD;AAED;;;;;;;AAOG;;;AACH,SAAS,yBAAT,CACE,OADF,EAEE,eAFF,EAGE,cAHF,EAG8C;AAE5C;AAFA,MAAA,cAAA,KAAA,KAAA,CAAA,EAAA;AAAA,IAAA,cAAA,GAAA,EAAA;AAA4C;;AAI5C,MAAM,mBAAmB,GAAG,qBAAqB,CAAC,eAAD,CAAjD;;AAEA,MAAI,QAAA,CAAA,QAAA,CAAS,OAAT,EAAkB,GAAlB,CAAJ,EAA4B;AAC1B,QACE,OAAO,CAAC,MAAR,KAAmB,CAAnB,IACA,OAAO,CAAC,CAAD,CAAP,KAAe,GADf,IAEA,cAAc,CAAC,MAAf,GAAwB,CAH1B,EAIE;AACA,UAAM,yBAAuB,GAAsC,QAAA,CAAA,KAAA,CACjE,QAAA,CAAA,OAAA,CAAQ,cAAc,CAAC,KAAf,CAAqB,CAArB,EAAwB,cAAc,CAAC,MAAf,GAAwB,CAAhD,CAAR,EAA4D,MAA5D,CACE,UAAA,GAAA,EAAG;AAAI,eAAA,CAAC,QAAA,CAAA,QAAA,CAAS,UAAT,EAAqB,GAAG,CAAC,IAAJ,CAAtB,KAAC,CAAD;AAAqC,OAD9C,CADiE,EAIjE,UAAA,GAAA,EAAG;AAAI,eAAA,GAAG,CAAC,IAAJ,CAAA,KAAA;AAAc,OAJ4C,CAAnE;AAMA,aAAO,eAAe,CAAC,MAAhB,CACL,UAAA,OAAA,EAAO;AACL,eAAA,OAAO,CAAC,IAAR,KAAiB,sBAAjB,IACA,yBAAuB,CAAC,OAAO,CAAC,IAAR,CAAa,KAAd,CADvB;AAC2C,OAHxC,CAAP;AAKD;;AACD,WAAO,mBAAP;AACD,GAnBD,MAmBO;AACL,QAAM,MAAM,GAAG,mBAAmB,CAAC,MAApB,CAA2B,UAAA,CAAA,EAAC;AACzC,aAAA,QAAA,CAAA,QAAA,CAAS,OAAO,CAAC,GAAR,CAAY,UAAA,CAAA,EAAC;AAAI,eAAA,CAAC,CAAC,KAAF,CAAQ,GAAR,EAAA,CAAA,CAAA;AAAe,OAAhC,CAAT,EAA4C,CAAC,CAAC,IAAF,CAAO,KAAnD,CAAA;AAAyD,KAD5C,CAAf;AAGA,QAAM,YAAY,GAAG,OAAO,CAAC,MAAR,CAAe,UAAA,CAAA,EAAC;AAAI,aAAA,CAAC,CAAC,KAAF,CAAQ,GAAR,EAAa,MAAb,GAAA,CAAA;AAAuB,KAA3C,CAArB;AACA,QAAM,mBAAmB,GAAG,QAAA,CAAA,OAAA,CAAQ,YAAR,EAAsB,UAAA,CAAA,EAAC;AAAI,aAAA,CAAC,CAAC,KAAF,CAAQ,GAAR,EAAA,CAAA,CAAA;AAAe,KAA1C,CAA5B;;4BAEW,Q,EAAQ;AACjB,UAAM,MAAM,GAAG,mBAAmB,CAAC,QAAD,CAAnB,CAA8B,GAA9B,CAAkC,UAAA,CAAA,EAAC;AAAI,eAAA,CAAC,CAAC,KAAF,CAAQ,GAAR,EAAA,CAAA,CAAA;AAAe,OAAtD,CAAf;AACE,MAAA,mBAAmB,CAAC,IAApB,CACA,UAAA,GAAA,EAAG;AAAI,eAAA,GAAG,CAAC,IAAJ,CAAS,KAAT,KAAA,QAAA;AAA2B,OADlC,EAEQ,MAFR,GAEkB,mBAAmB,CAAC,IAApB,CAClB,UAAA,GAAA,EAAG;AAAI,eAAA,GAAG,CAAC,IAAJ,CAAS,KAAT,KAAA,QAAA;AAA2B,OADhB,EAEW,MAFX,CAEkB,MAFlB,CAGlB,UAAA,CAAA,EAAC;AAAI,eAAA,QAAA,CAAA,QAAA,CAAS,MAAT,EAAiB,CAAC,CAAC,IAAF,CAAO,KAAxB,KAAkC,QAAA,CAAA,QAAA,CAAS,MAAT,EAAlC,GAAkC,CAAlC;AAAuD,OAH1C,CAFlB;AAOH,K;;AATD,SAAK,IAAM,QAAX,IAAuB,mBAAvB,EAA0C;cAA/B,Q;AASV;;AAED,WAAO,MAAP;AACD;AACF;AAED;;;;;AAKG;;;AACH,SAAS,qBAAT,CACE,WADF,EAC4C;AAE1C,MAAM,UAAU,GAAG,CACjB,qBADiB,EAEjB,sBAFiB,EAGjB,sBAHiB,EAIjB,yBAJiB,EAKjB,oBALiB,EAMjB,qBANiB,EAOjB,2BAPiB,CAAnB;AASA,SAAO,WAAW,CACf,MADI,CACG,UAAA,CAAA,EAAC;AAAI,WAAA,QAAA,CAAA,QAAA,CAAS,UAAT,EAAqB,CAAC,CAAtB,IAAA,CAAA;AAA4B,GADpC,EAEJ,GAFI,CAEA,UAAA,CAAA,EAAC;AAAI,WAAA,CAAA;AAAwB,GAF7B,CAAP;AAGD","sourceRoot":"","sourcesContent":["\"use strict\";\nvar __assign = (this && this.__assign) || function () {\n    __assign = Object.assign || function(t) {\n        for (var s, i = 1, n = arguments.length; i < n; i++) {\n            s = arguments[i];\n            for (var p in s) if (Object.prototype.hasOwnProperty.call(s, p))\n                t[p] = s[p];\n        }\n        return t;\n    };\n    return __assign.apply(this, arguments);\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nvar fs = require(\"fs\");\nvar graphql_1 = require(\"graphql\");\nvar lodash_1 = require(\"lodash\");\nvar path = require(\"path\");\nvar resolveFrom = require(\"resolve-from\");\nvar definition_1 = require(\"./definition\");\nvar rootFields = ['Query', 'Mutation', 'Subscription'];\nvar read = function (schema, schemas) {\n    if (isFile(schema)) {\n        return fs.readFileSync(schema, { encoding: 'utf8' });\n    }\n    return schemas ? schemas[schema] : schema;\n};\nvar isFile = function (f) { return f.endsWith('.graphql'); };\n/**\n * Parse a single import line and extract imported types and schema filename\n *\n * @param importLine Import line\n * @returns Processed import line\n */\nfunction parseImportLine(importLine) {\n    // Apply regex to import line\n    var matches = importLine.match(/^import (\\*|(.*)) from ('|\")(.*)('|\");?$/);\n    if (!matches || matches.length !== 6 || !matches[4]) {\n        throw new Error(\"Too few regex matches: \" + matches);\n    }\n    // Extract matches into named variables\n    var wildcard = matches[1], importsString = matches[2], from = matches[4];\n    // Extract imported types\n    var imports = wildcard === '*' ? ['*'] : importsString.split(',').map(function (d) { return d.trim(); });\n    // Return information about the import line\n    return { imports: imports, from: from };\n}\nexports.parseImportLine = parseImportLine;\n/**\n * Parse a schema and analyze all import lines\n *\n * @param sdl Schema to parse\n * @returns Array with collection of imports per import line (file)\n */\nfunction parseSDL(sdl) {\n    return sdl\n        .split('\\n')\n        .map(function (l) { return l.trim(); })\n        .filter(function (l) { return l.startsWith('# import ') || l.startsWith('#import '); })\n        .map(function (l) { return l.replace('#', '').trim(); })\n        .map(parseImportLine);\n}\nexports.parseSDL = parseSDL;\n/**\n * Main entry point. Recursively process all import statement in a schema\n *\n * @param filePath File path to the initial schema file\n * @returns Single bundled schema with all imported types\n */\nfunction importSchema(schema, schemas) {\n    var sdl = read(schema, schemas) || schema;\n    var document = getDocumentFromSDL(sdl);\n    // Recursively process the imports, starting by importing all types from the initial schema\n    var _a = collectDefinitions(['*'], sdl, schema, schemas), allDefinitions = _a.allDefinitions, typeDefinitions = _a.typeDefinitions;\n    // Post processing of the final schema (missing types, unused types, etc.)\n    // Query, Mutation and Subscription should be merged\n    // And should always be in the first set, to make sure they\n    // are not filtered out.\n    var firstTypes = lodash_1.flatten(typeDefinitions).filter(function (d) {\n        return lodash_1.includes(rootFields, d.name.value);\n    });\n    var otherFirstTypes = typeDefinitions[0].filter(function (d) { return !lodash_1.includes(rootFields, d.name.value); });\n    var firstSet = firstTypes.concat(otherFirstTypes);\n    var processedTypeNames = [];\n    var mergedFirstTypes = [];\n    var _loop_1 = function (type) {\n        if (!lodash_1.includes(processedTypeNames, type.name.value)) {\n            processedTypeNames.push(type.name.value);\n            mergedFirstTypes.push(type);\n        }\n        else {\n            var existingType = mergedFirstTypes.find(function (t) { return t.name.value === type.name.value; });\n            existingType.fields = existingType.fields.concat(type.fields);\n        }\n    };\n    for (var _i = 0, firstSet_1 = firstSet; _i < firstSet_1.length; _i++) {\n        var type = firstSet_1[_i];\n        _loop_1(type);\n    }\n    document = __assign({}, document, { definitions: definition_1.completeDefinitionPool(lodash_1.flatten(allDefinitions), firstSet, lodash_1.flatten(typeDefinitions)) });\n    // Return the schema as string\n    return graphql_1.print(document);\n}\nexports.importSchema = importSchema;\n/**\n * Parses a schema into a graphql DocumentNode.\n * If the schema is empty a DocumentNode with empty definitions will be created.\n *\n * @param sdl Schema to parse\n * @returns A graphql DocumentNode with definitions of the parsed sdl.\n */\nfunction getDocumentFromSDL(sdl) {\n    if (isEmptySDL(sdl)) {\n        return {\n            kind: graphql_1.Kind.DOCUMENT,\n            definitions: [],\n        };\n    }\n    else {\n        return graphql_1.parse(sdl, { noLocation: true });\n    }\n}\n/**\n * Check if a schema contains any type definitions at all.\n *\n * @param sdl Schema to parse\n * @returns True if SDL only contains comments and/or whitespaces\n */\nfunction isEmptySDL(sdl) {\n    return (sdl\n        .split('\\n')\n        .map(function (l) { return l.trim(); })\n        .filter(function (l) { return !(l.length === 0 || l.startsWith('#')); }).length === 0);\n}\n/**\n * Resolve the path of an import.\n * First it will try to find a file relative from the file the import is in, if that fails it will try to resolve it as a module so imports from packages work correctly.\n *\n * @param filePath Path the import was made from\n * @param importFrom Path given for the import\n * @returns Full resolved path to a file\n */\nfunction resolveModuleFilePath(filePath, importFrom) {\n    var dirname = path.dirname(filePath);\n    if (isFile(filePath) && isFile(importFrom)) {\n        try {\n            return fs.realpathSync(path.join(dirname, importFrom));\n        }\n        catch (e) {\n            if (e.code === 'ENOENT') {\n                return resolveFrom(dirname, importFrom);\n            }\n        }\n    }\n    return importFrom;\n}\n/**\n * Recursively process all schema files. Keeps track of both the filtered\n * type definitions, and all type definitions, because they might be needed\n * in post-processing (to add missing types)\n *\n * @param imports Types specified in the import statement\n * @param sdl Current schema\n * @param filePath File location for current schema\n * @param Tracking of processed schemas (for circular dependencies)\n * @param Tracking of imported type definitions per schema\n * @param Tracking of all type definitions per schema\n * @returns Both the collection of all type definitions, and the collection of imported type definitions\n */\nfunction collectDefinitions(imports, sdl, filePath, schemas, processedFiles, typeDefinitions, allDefinitions) {\n    if (processedFiles === void 0) { processedFiles = new Map(); }\n    if (typeDefinitions === void 0) { typeDefinitions = []; }\n    if (allDefinitions === void 0) { allDefinitions = []; }\n    var key = isFile(filePath) ? path.resolve(filePath) : filePath;\n    // Get TypeDefinitionNodes from current schema\n    var document = getDocumentFromSDL(sdl);\n    // Add all definitions to running total\n    allDefinitions.push(filterTypeDefinitions(document.definitions));\n    // Filter TypeDefinitionNodes by type and defined imports\n    var currentTypeDefinitions = filterImportedDefinitions(imports, document.definitions, allDefinitions);\n    // Add typedefinitions to running total\n    typeDefinitions.push(currentTypeDefinitions);\n    // Read imports from current file\n    var rawModules = parseSDL(sdl);\n    // Process each file (recursively)\n    rawModules.forEach(function (m) {\n        // If it was not yet processed (in case of circular dependencies)\n        var moduleFilePath = resolveModuleFilePath(filePath, m.from);\n        var processedFile = processedFiles.get(key);\n        if (!processedFile || !processedFile.find(function (rModule) { return lodash_1.isEqual(rModule, m); })) {\n            // Mark this specific import line as processed for this file (for cicular dependency cases)\n            processedFiles.set(key, processedFile ? processedFile.concat(m) : [m]);\n            collectDefinitions(m.imports, read(moduleFilePath, schemas), moduleFilePath, schemas, processedFiles, typeDefinitions, allDefinitions);\n        }\n    });\n    // Return the maps of type definitions from each file\n    return { allDefinitions: allDefinitions, typeDefinitions: typeDefinitions };\n}\n/**\n * Filter the types loaded from a schema, first by relevant types,\n * then by the types specified in the import statement.\n *\n * @param imports Types specified in the import statement\n * @param typeDefinitions All definitions from a schema\n * @returns Filtered collection of type definitions\n */\nfunction filterImportedDefinitions(imports, typeDefinitions, allDefinitions) {\n    // This should do something smart with fields\n    if (allDefinitions === void 0) { allDefinitions = []; }\n    var filteredDefinitions = filterTypeDefinitions(typeDefinitions);\n    if (lodash_1.includes(imports, '*')) {\n        if (imports.length === 1 &&\n            imports[0] === '*' &&\n            allDefinitions.length > 1) {\n            var previousTypeDefinitions_1 = lodash_1.keyBy(lodash_1.flatten(allDefinitions.slice(0, allDefinitions.length - 1)).filter(function (def) { return !lodash_1.includes(rootFields, def.name.value); }), function (def) { return def.name.value; });\n            return typeDefinitions.filter(function (typeDef) {\n                return typeDef.kind === 'ObjectTypeDefinition' &&\n                    previousTypeDefinitions_1[typeDef.name.value];\n            });\n        }\n        return filteredDefinitions;\n    }\n    else {\n        var result = filteredDefinitions.filter(function (d) {\n            return lodash_1.includes(imports.map(function (i) { return i.split('.')[0]; }), d.name.value);\n        });\n        var fieldImports = imports.filter(function (i) { return i.split('.').length > 1; });\n        var groupedFieldImports = lodash_1.groupBy(fieldImports, function (x) { return x.split('.')[0]; });\n        var _loop_2 = function (rootType) {\n            var fields = groupedFieldImports[rootType].map(function (x) { return x.split('.')[1]; });\n            filteredDefinitions.find(function (def) { return def.name.value === rootType; }).fields = filteredDefinitions.find(function (def) { return def.name.value === rootType; }).fields.filter(function (f) { return lodash_1.includes(fields, f.name.value) || lodash_1.includes(fields, '*'); });\n        };\n        for (var rootType in groupedFieldImports) {\n            _loop_2(rootType);\n        }\n        return result;\n    }\n}\n/**\n * Filter relevant definitions from schema\n *\n * @param definitions All definitions from a schema\n * @returns Relevant type definitions\n */\nfunction filterTypeDefinitions(definitions) {\n    var validKinds = [\n        'DirectiveDefinition',\n        'ScalarTypeDefinition',\n        'ObjectTypeDefinition',\n        'InterfaceTypeDefinition',\n        'EnumTypeDefinition',\n        'UnionTypeDefinition',\n        'InputObjectTypeDefinition',\n    ];\n    return definitions\n        .filter(function (d) { return lodash_1.includes(validKinds, d.kind); })\n        .map(function (d) { return d; });\n}\n//# sourceMappingURL=index.js.map"]},"metadata":{},"sourceType":"script"}